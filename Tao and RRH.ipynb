{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9944a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6cb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred - true) ** 2)\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "def MSPE(pred, true):\n",
    "    return np.mean(np.square((pred - true) / true))\n",
    "\n",
    "def DA(pred, true):\n",
    "    da = (pred[1:] - true[:-1]) * (true[1:] - pred[:-1]) > 0\n",
    "    return da.mean()\n",
    "\n",
    "def metric(pred, true):\n",
    "    mae = MAE(pred, true)\n",
    "    mse = MSE(pred, true)\n",
    "    rmse = RMSE(pred, true)\n",
    "    mape = MAPE(pred, true)\n",
    "    mspe = MSPE(pred, true)\n",
    "    da = DA(pred, true)\n",
    "    \n",
    "    return mae, mse, rmse, mape, mspe, da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd994ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r'datasets/gefcom2017.csv'\n",
    "\n",
    "df = pd.read_csv(data_path, encoding='gb18030')\n",
    "# df['trend'] = range(1,len(df)+1)\n",
    "# df = df[['trend','ts', 'zone', 'demand', 'drybulb', 'dewpnt', ]]\n",
    "df = df[['ts', 'trend', 'zone', 'demand', 'drybulb', 'dewpnt' ]]\n",
    "df['ts'] = pd.to_datetime(df['ts'])\n",
    "\n",
    "\n",
    "df['drybulb^2'] = df['drybulb'].apply(lambda x: x**2)\n",
    "df['drybulb^3'] = df['drybulb'].apply(lambda x: x**3)\n",
    "\n",
    "\n",
    "df['RH'] = 100 * ( ((17.27 * ((df['dewpnt'] - 32 )/1.8) ) / (\n",
    "    ((df['dewpnt'] - 32 )/1.8) + 237.3)).apply(math.exp) / (\n",
    "    (17.27 * ((df['drybulb'] - 32 )/1.8) ) / (\n",
    "         ((df['drybulb'] - 32 )/1.8) + 237.3)).apply(math.exp) )\n",
    "df['RH^2'] = df['RH'].apply(lambda x: x**2)\n",
    "df['RH^3'] = df['RH'].apply(lambda x: x**3)\n",
    "df = df.drop(columns=['dewpnt'])\n",
    "\n",
    "\n",
    "df['month'] = df['ts'].apply(lambda x: x.month - 1)\n",
    "df['week'] = df['ts'].apply(lambda x: x.weekday())\n",
    "df['hour'] = df['ts'].apply(lambda x: x.hour)\n",
    "\n",
    "start = pd.Timestamp(2008, 1, 1)\n",
    "end = pd.Timestamp(2017, 1, 1)\n",
    "df = df.loc[df['ts'].apply(lambda x: start<= x < end )]\n",
    "\n",
    "df['S'] = df['month'].apply(lambda x: 1 if x in [6,7,8,9] else 0)\n",
    "\n",
    "\n",
    "data_path=r'datasets/ISONE2017-2024.csv'\n",
    "\n",
    "df2 = pd.read_csv(data_path, encoding='gb18030')\n",
    "df2['ts'] = df2['ts'].apply(lambda x: pd.Timestamp(x) )\n",
    "\n",
    "# start = pd.Timestamp(2018, 1, 1)\n",
    "# end = pd.Timestamp(2020, 1, 1)\n",
    "# df2 = df2.loc[df2['ts'].apply(lambda x: start<= x < end )]\n",
    "\n",
    "df2['RH'] = 100 * ( ((17.27 * ((df2['dewpnt'] - 32 )/1.8) ) / (\n",
    "    ((df2['dewpnt'] - 32 )/1.8) + 237.3)).apply(math.exp) / (\n",
    "    (17.27 * ((df2['drybulb'] - 32 )/1.8) ) / (\n",
    "         ((df2['drybulb'] - 32 )/1.8) + 237.3)).apply(math.exp) )\n",
    "\n",
    "df2 = df2.drop(columns=['dewpnt'])\n",
    "\n",
    "df2['drybulb^2'] = df2['drybulb'].apply(lambda x: x**2)\n",
    "df2['drybulb^3'] = df2['drybulb'].apply(lambda x: x**3)\n",
    "\n",
    "df2['RH^2'] = df2['RH'].apply(lambda x: x**2)\n",
    "df2['RH^3'] = df2['RH'].apply(lambda x: x**3)\n",
    "\n",
    "df2 = df2[['ts',  'zone', 'demand', 'drybulb', 'RH', 'drybulb^2', 'drybulb^3', 'RH^2', 'RH^3', 'month', 'week', 'hour']]\n",
    "\n",
    "df2['S'] = df2['month'].apply(lambda x: 1 if x in [6,7,8,9] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5433210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_zone_trainMLR(df1,df2, zone, train_start, train_end, valid_start, valid_end, test_start, test_end, log=False, num_hour = 3, num_day = 1, RH = False):\n",
    "    if zone != 'MASS':\n",
    "        df_ct1 = df1.groupby('zone').get_group(zone)\n",
    "        df_ct2 = df2.groupby('zone').get_group(zone)\n",
    "        df_ct = pd.concat([df_ct1, df_ct2])\n",
    "    else:\n",
    "        df_ct = df1.groupby('zone').get_group(zone)\n",
    "        \n",
    "    df_ct = df_ct.drop(columns=['zone'])\n",
    "    df_ct = df_ct.loc[df_ct['ts'].apply(lambda x: train_start - datetime.timedelta(days=240) <= x < test_end )]\n",
    "    \n",
    "    df_ct['trend'] = range(1,len(df_ct)+1)\n",
    "    df_ct = df_ct[['trend', 'ts' , 'demand', 'drybulb','drybulb^2', 'drybulb^3','RH','RH^2','RH^3','S', 'month', 'week', 'hour']] \n",
    "        \n",
    "    df_ct['hour_week'] = df_ct['week'].astype(str) + '_' + df_ct['hour'].astype(str)\n",
    "    df_ct = pd.get_dummies(df_ct, columns = ['month', 'hour', 'week', 'hour_week'])\n",
    "\n",
    "    if RH == True:\n",
    "        for i in range(24):\n",
    "            cp = df_ct.copy()\n",
    "            cp['RH_S_hour_{}'.format(i)] = cp['RH'] * cp['S'] * cp['hour_{}'.format(i)]\n",
    "            cp['RH_S^2_hour_{}'.format(i)] = (cp['RH']**2) * (cp['S']) * cp['hour_{}'.format(i)]\n",
    "            df_ct = cp\n",
    "        cp['RH_S'] = cp['RH'] * cp['S']\n",
    "        cp['RH_S^2'] = (cp['RH']**2) * (cp['S'])\n",
    "        df_ct = cp\n",
    "        cp['drybulb_RH_S'] = cp['drybulb'] * cp['RH'] * cp['S']\n",
    "        cp['drybulb^2_RH_S'] = (cp['drybulb']**2) * cp['RH'] * cp['S']\n",
    "        df_ct = cp\n",
    "        cp['drybulb_RH_S^2'] = cp['drybulb'] * cp['S'] * (cp['RH']**2)\n",
    "        cp['drybulb^2_RH_S^2'] = (cp['drybulb']**2) * cp['S'] * (cp['RH']**2)\n",
    "        df_ct = cp\n",
    "        df_ct = df_ct.drop(columns=['RH', 'RH^2', 'RH^3','S'])\n",
    "        \n",
    "    else:\n",
    "        df_ct = df_ct.drop(columns=['RH', 'RH^2', 'RH^3','S'])\n",
    "\n",
    "    for i in range(12):\n",
    "        cp = df_ct.copy()\n",
    "        cp['drybulb_month_{}'.format(i)] = cp['drybulb'] * cp['month_{}'.format(i)]\n",
    "        cp['drybulb^2_month_{}'.format(i)] = cp['drybulb^2'] * cp['month_{}'.format(i)]\n",
    "        cp['drybulb^3_month_{}'.format(i)] = cp['drybulb^3'] * cp['month_{}'.format(i)]\n",
    "        df_ct = cp\n",
    "    for i in range(24):\n",
    "        cp = df_ct.copy()\n",
    "        cp['drybulb_hour_{}'.format(i)] = cp['drybulb'] * cp['hour_{}'.format(i)]\n",
    "        cp['drybulb^2_hour_{}'.format(i)] = cp['drybulb^2'] * cp['hour_{}'.format(i)]\n",
    "        cp['drybulb^3_hour_{}'.format(i)] = cp['drybulb^3'] * cp['hour_{}'.format(i)]\n",
    "        df_ct = cp\n",
    "        \n",
    "    for i in range(num_hour):\n",
    "        df_ct['drybulb_lag{}'.format(i+1)] = df_ct['drybulb'].shift(axis=0, periods=i+1)\n",
    "        df_ct['drybulb^2_lag{}'.format(i+1)] = df_ct['drybulb^2'].shift(axis=0, periods=i+1)\n",
    "        df_ct['drybulb^3_lag{}'.format(i+1)] = df_ct['drybulb^3'].shift(axis=0, periods=i+1)\n",
    "        for p in range(12):\n",
    "            cp = df_ct.copy()\n",
    "            cp['drybulb_lag{}_month_{}'.format(i+1, p)] = cp['drybulb_lag{}'.format(i+1)] * cp['month_{}'.format(p)]\n",
    "            cp['drybulb^2_lag{}_month_{}'.format(i+1, p)] = cp['drybulb^2_lag{}'.format(i+1)] * cp['month_{}'.format(p)]\n",
    "            cp['drybulb^3_lag{}_month_{}'.format(i+1, p)] = cp['drybulb^3_lag{}'.format(i+1)] * cp['month_{}'.format(p)]\n",
    "            df_ct = cp\n",
    "        for q in range(24):\n",
    "            cp = df_ct.copy()\n",
    "            cp['drybulb_lag{}_hour_{}'.format(i+1, q+1)] = cp['drybulb_lag{}'.format(i+1)] * cp['hour_{}'.format(q)]\n",
    "            cp['drybulb^2_lag{}_hour_{}'.format(i+1, q+1)] = cp['drybulb^2_lag{}'.format(i+1)] * cp['hour_{}'.format(q)]\n",
    "            cp['drybulb^3_lag{}_hour_{}'.format(i+1, q+1)] = cp['drybulb^3_lag{}'.format(i+1)] * cp['hour_{}'.format(q)]\n",
    "            df_ct = cp\n",
    "        df_ct = df_ct.drop(columns=['drybulb_lag{}_hour_{}'.format(i+1, q+1)])\n",
    "        df_ct = df_ct.drop(columns=['drybulb^2_lag{}_hour_{}'.format(i+1, q+1)])\n",
    "        df_ct = df_ct.drop(columns=['drybulb^3_lag{}_hour_{}'.format(i+1, q+1)])\n",
    "\n",
    "    for k in range(num_day):\n",
    "        df_ct['drybulb^a_lag{}'.format(k)] = 0\n",
    "        for j in range(24):\n",
    "            df_ct['drybulb^a_lag{}'.format(k)] += df_ct['drybulb'].shift(axis=0, periods= 24 * k + j + 1)\n",
    "\n",
    "        df_ct['drybulb^a_lag{}'.format(k)] /= 24\n",
    "\n",
    "        df_ct['drybulb^a^2_lag{}'.format(k)] = df_ct['drybulb^a_lag{}'.format(k)].apply(lambda x: x**2)\n",
    "        df_ct['drybulb^a^3_lag{}'.format(k)] = df_ct['drybulb^a_lag{}'.format(k)].apply(lambda x: x**3)\n",
    "        \n",
    "        for p in range(12):\n",
    "            cp = df_ct.copy()\n",
    "            cp['drybulb^a_lag{}_month_{}'.format(k, p)] = cp['drybulb^a_lag{}'.format(k)] * cp['month_{}'.format(p)]\n",
    "            cp['drybulb^a^2_lag{}_month_{}'.format(k, p)] = cp['drybulb^a^2_lag{}'.format(k)] * cp['month_{}'.format(p)]\n",
    "            cp['drybulb^a^3_lag{}_month_{}'.format(k, p)] = cp['drybulb^a^3_lag{}'.format(k)] * cp['month_{}'.format(p)]\n",
    "            df_ct = cp\n",
    "        for q in range(24):\n",
    "            cp = df_ct.copy()\n",
    "            cp['drybulb^a_lag{}_hour_{}'.format(k, q+1)] = cp['drybulb^a_lag{}'.format(k)] * cp['hour_{}'.format(q)]\n",
    "            cp['drybulb^a^2_lag{}_hour_{}'.format(k, q+1)] = cp['drybulb^a^2_lag{}'.format(k)] * cp['hour_{}'.format(q)]\n",
    "            cp['drybulb^a^3_lag{}_hour_{}'.format(k, q+1)] = cp['drybulb^a^3_lag{}'.format(k)] * cp['hour_{}'.format(q)]\n",
    "            df_ct = cp\n",
    "            \n",
    "        df_ct = df_ct.drop(columns=['drybulb^a_lag{}'.format(k)])\n",
    "        df_ct = df_ct.drop(columns=['drybulb^a^2_lag{}'.format(k)])\n",
    "        df_ct = df_ct.drop(columns=['drybulb^a^3_lag{}'.format(k)])\n",
    "\n",
    "    # drop unused variables.\n",
    "    to_drop = [\"week_{}\".format(i) for i in range(7)\n",
    "              ] + [\"hour_{}\".format(i) for i in range(24)] + [\n",
    "                  \"drybulb\", \"drybulb^2\", \"drybulb^3\"]\n",
    "    df_ct = df_ct.drop(columns=to_drop)\n",
    "    \n",
    "    train_data = df_ct.loc[df_ct['ts'].apply(lambda x: train_start <= x < train_end)]\n",
    "    valid_data = df_ct.loc[df_ct['ts'].apply(lambda x: valid_start <= x < valid_end)]\n",
    "    test_data = df_ct.loc[df_ct['ts'].apply(lambda x: test_start <= x < test_end)]\n",
    "    \n",
    "    X_train, y_train = train_data.drop(columns=['ts', 'demand']\n",
    "                                      ).values.copy(), train_data['demand'].values.copy()\n",
    "    X_valid, y_valid = valid_data.drop(columns=['ts', 'demand']\n",
    "                                      ).values.copy(), valid_data['demand'].values.copy()\n",
    "    X_test, y_test = test_data.drop(columns=['ts', 'demand']\n",
    "                                   ).values.copy(), test_data['demand'].values.copy()\n",
    "    if log:\n",
    "        print(\"zone: {}, \\n\\t Train start: {}, \\n\\t Train end: {}\".format(zone, train_start, train_end))\n",
    "        print(\"zone: {}, \\n\\t Valid start: {}, \\n\\t Valid end: {}\".format(zone, valid_start, valid_end))\n",
    "        print(\"zone: {}, \\n\\t Test start: {}, \\n\\t Test end: {}\".format(zone, test_start, test_end))\n",
    "        print(\"Train set:\", X_train.shape)\n",
    "        print(\"Valid set:\", X_valid.shape)\n",
    "        print(\"Test set:\", X_test.shape)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tao and RRH\n",
    "\n",
    "start_year = 2015\n",
    "\n",
    "Poly_benchmark_dict = {}\n",
    "\n",
    "for zone in ['CT', 'ME', 'NEMASSBOST', 'NH', 'RI', 'SEMASS','VT', 'WCMASS', 'TOTAL']:\n",
    "\n",
    "    Poly_benchmark_subdict = {}\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = get_zone_trainMLR(\n",
    "        df, df2, zone=zone,\n",
    "        train_start = pd.Timestamp(start_year, 1, 1),\n",
    "        train_end = pd.Timestamp(start_year + 2, 1, 1),\n",
    "        valid_start = pd.Timestamp(start_year + 2, 1, 1),\n",
    "        valid_end = pd.Timestamp(start_year + 3, 1, 1),\n",
    "        test_start = pd.Timestamp(start_year + 3, 1, 1),\n",
    "        test_end = pd.Timestamp(start_year + 4, 1, 1),\n",
    "        log=True, num_hour = 0, num_day = 0, RH = False\n",
    "    )\n",
    "\n",
    "    train_features = X_train.astype(np.float64)\n",
    "    valid_features = X_valid.astype(np.float64)\n",
    "    test_features = X_test.astype(np.float64)\n",
    "\n",
    "    train_labels = y_train.astype(np.float64)\n",
    "    valid_labels = y_valid.astype(np.float64)\n",
    "    test_labels = y_test.astype(np.float64)\n",
    "\n",
    "    [m_train, n_train] = train_features.shape\n",
    "    [m_valid, n_valid] = valid_features.shape\n",
    "    [m_test, n_test] = test_features.shape\n",
    "\n",
    "    X_all = np.concatenate((train_features, valid_features, test_features), axis = 0)\n",
    "    m = X_all.shape[0]\n",
    "    mins = np.min(X_all[0:(m_train + m_valid), :], axis = 0)\n",
    "    maxs = np.max(X_all[0:(m_train + m_valid), :], axis = 0)\n",
    "\n",
    "    for i in range(m):\n",
    "        X_all[i,:] = (X_all[i,:] - mins) / (maxs - mins)\n",
    "\n",
    "    train_features = X_all[:m_train, :]\n",
    "    valid_features = X_all[m_train:(m_train + m_valid), :]\n",
    "    test_features = X_all[(m_train + m_valid) :,:]\n",
    "\n",
    "    # Since the validation set is unnecessary, it is merged with the training set.\n",
    "    X_train_valid = np.concatenate((train_features, valid_features), axis = 0)\n",
    "    y_train_valid = np.concatenate((train_labels, valid_labels), axis = 0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train_valid, y_train_valid)\n",
    "    y_test_pred = model.predict(test_features)\n",
    "    preTao = y_test_pred\n",
    "\n",
    "    test_rmse = RMSE(preTao, y_test)\n",
    "    test_mape = MAPE(preTao, y_test)\n",
    "    daily_peak_rmse = RMSE( np.max(preTao.reshape(-1,24) , axis = 1) , np.max(y_test.reshape(-1,24) , axis = 1) )\n",
    "    daily_peak_mape =  MAPE( np.max(preTao.reshape(-1,24) , axis = 1) , np.max(y_test.reshape(-1,24) , axis = 1) )\n",
    "\n",
    "    print('zone', zone)\n",
    "    print('Tao')\n",
    "    print('RMSE', test_rmse)\n",
    "    print('Daily Peak MAPE', daily_peak_mape)\n",
    "\n",
    "    Poly_benchmark_subdict['Tao'] = {\n",
    "                        \"test rmse\": test_rmse,\n",
    "                        \"test mape\": test_mape,\n",
    "                        'daily_peak_rmse': daily_peak_rmse,\n",
    "                        'daily_peak_mape': daily_peak_mape,\n",
    "                        \"test_preds\": y_test_pred,\n",
    "                        \"test_trajs\": y_test,\n",
    "                    }\n",
    "    \n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = get_zone_trainMLR(\n",
    "        df, df2, zone=zone,\n",
    "        train_start = pd.Timestamp(start_year, 1, 1),\n",
    "        train_end = pd.Timestamp(start_year + 2, 1, 1),\n",
    "        valid_start = pd.Timestamp(start_year + 2, 1, 1),\n",
    "        valid_end = pd.Timestamp(start_year + 3, 1, 1),\n",
    "        test_start = pd.Timestamp(start_year + 3, 1, 1),\n",
    "        test_end = pd.Timestamp(start_year + 4, 1, 1),\n",
    "        log=True, num_hour = 12, num_day = 2, RH = True\n",
    "    )\n",
    "\n",
    "    train_features = X_train.astype(np.float64)\n",
    "    valid_features = X_valid.astype(np.float64)\n",
    "    test_features = X_test.astype(np.float64)\n",
    "\n",
    "    train_labels = y_train.astype(np.float64)\n",
    "    valid_labels = y_valid.astype(np.float64)\n",
    "    test_labels = y_test.astype(np.float64)\n",
    "\n",
    "    [m_train, n_train] = train_features.shape\n",
    "    [m_valid, n_valid] = valid_features.shape\n",
    "    [m_test, n_test] = test_features.shape\n",
    "\n",
    "    X_all = np.concatenate((train_features, valid_features, test_features), axis = 0)\n",
    "    m = X_all.shape[0]\n",
    "    mins = np.min(X_all[0:(m_train + m_valid), :], axis = 0)\n",
    "    maxs = np.max(X_all[0:(m_train + m_valid), :], axis = 0)\n",
    "\n",
    "    for i in range(m):\n",
    "        X_all[i,:] = (X_all[i,:] - mins) / (maxs - mins)\n",
    "\n",
    "    train_features = X_all[:m_train, :]\n",
    "    valid_features = X_all[m_train:(m_train + m_valid), :]\n",
    "    test_features = X_all[(m_train + m_valid) :,:]\n",
    "\n",
    "    # Since the validation set is unnecessary, it is merged with the training set.\n",
    "    X_train_valid = np.concatenate((train_features, valid_features), axis = 0)\n",
    "    y_train_valid = np.concatenate((train_labels, valid_labels), axis = 0)\n",
    "\n",
    "    model = LinearRegression().fit(X_train_valid, y_train_valid)\n",
    "    y_test_pred = model.predict(test_features)\n",
    "    preTao = y_test_pred\n",
    "\n",
    "    test_rmse = RMSE(preTao, y_test)\n",
    "    test_mape = MAPE(preTao, y_test)\n",
    "    daily_peak_rmse = RMSE( np.max(preTao.reshape(-1,24) , axis = 1) , np.max(y_test.reshape(-1,24) , axis = 1) )\n",
    "    daily_peak_mape =  MAPE( np.max(preTao.reshape(-1,24) , axis = 1) , np.max(y_test.reshape(-1,24) , axis = 1) )\n",
    "\n",
    "\n",
    "    print('zone', zone)\n",
    "    print('RRH')\n",
    "    print('RMSE', test_rmse)\n",
    "    print('Daily Peak MAPE', daily_peak_mape)\n",
    "\n",
    "    Poly_benchmark_subdict['RRH'] = {\n",
    "                        \"test rmse\": test_rmse,\n",
    "                        \"test mape\": test_mape,\n",
    "                        'daily_peak_rmse': daily_peak_rmse,\n",
    "                        'daily_peak_mape': daily_peak_mape,\n",
    "                        \"test_preds\": y_test_pred,\n",
    "                        \"test_trajs\": y_test,\n",
    "                    }\n",
    "    \n",
    "    Poly_benchmark_dict[zone] = Poly_benchmark_subdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df79353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
